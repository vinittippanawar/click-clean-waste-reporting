# ğŸš€ Click & Clean â€” Serverless Waste Reporting System (AWS S3 + Lambda + API Gateway + DynamoDB + SES)

A fully deployed **serverless waste-reporting application** built on AWS.  
Users upload a photo, fill details, submit a report, and an email notification is sent automatically.

This project uses:

- **S3** â†’ Frontend hosting + Waste photo uploads  
- **API Gateway** â†’ Public API endpoints  
- **Lambda** â†’ Backend logic (upload URL + create report)  
- **DynamoDB** â†’ Store reports  
- **SES** â†’ Send email notifications  
- **IAM** â†’ Permissions & access control  

---

# ğŸŒŸ 1. Architecture Overview
```
Frontend (S3 Static Website)
â†“
API Gateway (POST /upload-url, POST /reports)
â†“
Lambda Functions
â€¢ GenerateUploadUrl
â€¢ CreateReport
â†“
S3 Bucket (Waste Photos)
â†“
DynamoDB (WasteReports table)
â†“
SES (Admin + User Emails)
```

# â­ Step 1 â€” Create S3 Buckets (Frontend + File Uploads)

You need **two S3 buckets** for this project:

---

## ğŸŸ¢ 1) S3 Bucket for Frontend Hosting  
This bucket will store your HTML, CSS, JS files.

**Bucket name : click-clean-frontend** 

Enable:
- **Static website hosting**
- **Public read access**

## ğŸŸ¢ 2) S3 Bucket for Photo Uploads

This bucket stores uploaded waste images using pre-signed URLs.

**Bucket name :click-and-clean-uploads**

 Keep Block Public Access = ON
(Users upload using pre-signed URLs, no need for public access.)

ğŸ“ Add CORS to Uploads Bucket

**Go to bucket â†’ Permissions â†’ CORS â†’ Paste:**
```
[
  {
    "AllowedHeaders": ["*"],
    "AllowedMethods": ["PUT", "GET"],
    "AllowedOrigins": ["*"],
    "ExposeHeaders": []
  }
]
```
**ğŸ“¸ CORS Settings Screenshot**


# â­ Step 2 â€” Create DynamoDB Table (WasteReports)

Your application needs one DynamoDB table to store all submitted waste reports.

Follow these steps:

# 1ï¸âƒ£ Create DynamoDB Table
- Go to **AWS Console â†’ DynamoDB â†’ Create Table**
- Use the following settings:
  
Table name: WasteReports

Partition key: reportId (String)

# 2ï¸âƒ£ Table Structure

Each report stored will automatically contain:

reportId (UUID)

city

area

description

wasteType

urgency

photoKey (S3 path)

timestamp

status (Default: "Pending")

**EXAMPLE ITEM**
```
{
  "reportId": "1234-5678-9999",
  "city": "Pune",
  "area": "Shivajinagar",
  "description": "Garbage collected near footpath",
  "wasteType": "Garbage",
  "urgency": "Medium",
  "photoKey": "reports/garbage.jpg",
  "timestamp": 1733840000,
  "status": "Pending"
}
```
# 3ï¸âƒ£ No Indexes Needed

This project only requires the primary key.

No secondary indexes or sort keys are needed for basic reporting.


# 4ï¸âƒ£ Verify Table is Created

Go to: 
```
DynamoDB â†’ Tables â†’ WasteReports â†’ Explore Table Items
```
You will see entries appear after each successful report submission

# â­ Step 3 â€” Create Lambda Function: GenerateUploadUrl (S3 Pre-Signed Uploads)

  This Lambda function generates a secure pre-signed URL so the user can upload photos directly to S3 without exposing your AWS keys.

 # ğŸŸ¢ 1ï¸âƒ£ Create Lambda Function

 Go to:
```
 AWS â†’ Lambda â†’ Create function
```
Choose:
```
Function name: GenerateUploadUrl
Runtime: Python 3.11
Architecture: x86_64
Permissions: Create new role with basic Lambda permissions
```
# ğŸŸ¢ 2ï¸âƒ£ Add Environment Variable

Go to:
```
Configuration â†’ Environment variables â†’ Edit
```
Add:

| Key           | Value                   |
| ------------- | ----------------------- |
| UPLOAD_BUCKET | click-and-clean-uploads |

Save.

# ğŸŸ¢ 3ï¸âƒ£ Paste Lambda Code

Replace existing code with:
```
import json
import boto3
import os
from botocore.exceptions import ClientError

S3_BUCKET = os.environ["UPLOAD_BUCKET"]
s3_client = boto3.client("s3")

def lambda_handler(event, context):
    body = json.loads(event.get("body") or "{}")

    file_name = body.get("fileName")
    content_type = body.get("contentType")

    if not file_name or not content_type:
        return {
            "statusCode": 400,
            "headers": {"Access-Control-Allow-Origin": "*"},
            "body": json.dumps({"error": "Missing fileName or contentType"})
        }

    file_key = f"reports/{file_name}"

    try:
        upload_url = s3_client.generate_presigned_url(
            "put_object",
            Params={
                "Bucket": S3_BUCKET,
                "Key": file_key,
                "ContentType": content_type
            },
            ExpiresIn=3600
        )

        return {
            "statusCode": 200,
            "headers": {"Access-Control-Allow-Origin": "*"},
            "body": json.dumps({"uploadUrl": upload_url, "fileKey": file_key})
        }

    except ClientError as e:
        return {
            "statusCode": 500,
            "headers": {"Access-Control-Allow-Origin": "*"},
            "body": json.dumps({"error": str(e)})
        }
```

Click Deploy.

# ğŸŸ¢ 4ï¸âƒ£ Add S3 Permissions to Lambda Role

Go to:
 ```
   Configuration â†’ Permissions â†’ Role name 
 ```
Then: 
```
 Add permissions â†’ Attach policies
```
Attach:
```
AmazonS3FullAccess
```
